{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import hashlib\n",
    "import os \n",
    "from utils import logger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import logger\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lassoSelection(X_train, y_train, n):\n",
    "    '''\n",
    "    Lasso feature selection.  Select n features. \n",
    "    '''\n",
    "    #lasso feature selection\n",
    "    #print (X_train)\n",
    "    clf = LassoCV(max_iter=10000,tol=0.001)\n",
    "    sfm = SelectFromModel(clf,threshold=0)\n",
    "    sfm.fit(X_train, y_train)\n",
    "    X_transform = sfm.transform(X_train)\n",
    "    n_features = X_transform.shape[1]\n",
    "\n",
    "    # \tprint(\"n_features=\",n_features)\n",
    "    #print(n_features)\n",
    "    while n_features > n:\n",
    "        sfm.threshold += 0.01\n",
    "        X_transform = sfm.transform(X_train)\n",
    "        n_features = X_transform.shape[1]\n",
    "        print (\"n_features =\",n_features)\n",
    "    features = [index for index,value in enumerate(sfm.get_support()) if value == True  ]\n",
    "    logger.info(\"selected features are {}\".format(features))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaSelection(X_train, X_test, n):\n",
    "    '''\n",
    "    PCA feature selection.  Select n features. \n",
    "    '''\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_train)\n",
    "    X_train_new = pca.transform(X_train)\n",
    "    X_test_new = pca.transform(X_test)\n",
    "    logger.info(\"X_train size after PCA: {}\".format(X_train_new.shape))\n",
    "    logger.info(\"X_test size after PCA: {}\".format(X_test_new.shape))\n",
    "    return [X_train_new,X_test_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsneSelection(X_train, X_test, n):\n",
    "    '''\n",
    "    t-distributed Stochastic Neighbor Embedding feature selection.  Select n features. \n",
    "    '''\n",
    "    tsne = TSNE(n_components=n)\n",
    "    tsne.fit(X_train)\n",
    "    X_train_new = tsne.transform(X_train)\n",
    "    X_test_new = tsne.transform(X_test)\n",
    "    logger.info(\"X_train size after PCA: {}\".format(X_train_new.shape))\n",
    "    logger.info(\"X_test size after PCA: {}\".format(X_test_new.shape))\n",
    "    return [X_train_new,X_test_new]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_predict(X_train,X_test,y_train,y_test):\n",
    "\n",
    "    # np.random.seed(2018)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(random_state=0, multi_class='ovr',solver='newton-cg',max_iter=10000,tol=0.001),\n",
    "        'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "        'RandomForestClassifier': RandomForestClassifier(),\n",
    "    #   \t# 'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "        # 'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "        'SVC': SVC(decision_function_shape='ovo',max_iter=10000,tol=0.001)\n",
    "    }\n",
    "    tuned_parameters = {\n",
    "        'LogisticRegression':{'C': [1, 10]},\n",
    "        # 'LogisticRegression':{'solver':['newton-cg','liblinear','sag'],'C': [1, 10]}\n",
    "        'ExtraTreesClassifier': { 'n_estimators': [100] },\n",
    "        'RandomForestClassifier': { 'n_estimators': [16, 32] },\n",
    "    #   \t'AdaBoostClassifier': { 'n_estimators': [16, 32] },\n",
    "        # 'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.05] },\n",
    "        # 'GradientBoostingClassifier': { 'n_estimators': [16, 32], 'learning_rate': [0.8, 1.0] },\n",
    "        'SVC': {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]}\n",
    "    }\n",
    "    scores= {}\n",
    "    for key in models:\n",
    "        print(\"Running\",key,\"...\")\n",
    "        clf = GridSearchCV(models[key], tuned_parameters[key], scoring=None,  refit=True, cv=10)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "        precision = precision_score(y_test, y_test_predict,average='micro') # tp / (tp + fp)\n",
    "        accuracy = accuracy_score(y_test, y_test_predict) #subset accuracy\n",
    "        f1 = f1_score(y_test, y_test_predict,average='micro') # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "        recall = recall_score(y_test, y_test_predict, average='macro') \n",
    "        # specificity = specificity_score(y_test, y_test_predict)\n",
    "        scores[key] = [precision,accuracy,f1,recall]\n",
    "    print(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "### Separate X (features) and y (labels)\n",
    "### Split training (70%) and testing (30%) dataset\n",
    "### Standardize data -- scale features such that they are 1) zero-mean, 2) one-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/miRNA.csv\" # directory to miRNA_matrix.csv\n",
    "\n",
    "df = pd.read_csv(data_file)\n",
    "# print(df)\n",
    "y_data = df.pop('label').values\n",
    "\n",
    "df.pop('file_id')\n",
    "\n",
    "columns =df.columns\n",
    "#print (columns)\n",
    "X_data = df.values\n",
    "\n",
    "print (\"Original dataset size:\",X_data.shape[0])\n",
    "print (\"Total feature num:\",X_data.shape[1])\n",
    "\n",
    "# split the data to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0)\n",
    "print(\"Training dataset size:\",X_train.shape[0])\n",
    "print(\"Testing dataset size:\", X_test.shape[0])\n",
    "# print(columns)\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "\n",
    "# standardize the data (zero-mean,uniform variance)\n",
    "print (\"pre-processing data...\")\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train.astype(np.float64))\n",
    "X_train = scaler.transform(X_train.astype(np.float64))\n",
    "X_test = scaler.transform(X_test.astype(np.float64))\n",
    "# print (X_train.mean(axis=0))\n",
    "# print(X_train.std(axis=0))\n",
    "\n",
    "# check the distribution of tumor and normal sampels in traing and test data set.\n",
    "# logger.info(\"Percentage of tumor cases in training set is {}\".format(sum(y_train)/len(y_train)))\n",
    "# logger.info(\"Percentage of tumor cases in test set is {}\".format(sum(y_test)/len(y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction/Selection\n",
    "### Lasso\n",
    "### PCA\n",
    "### PCA + tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO feature selection\n",
    "n = 50\n",
    "feaures_columns = lassoSelection(X_train, y_train, n)\n",
    "# feaures_columns = [25, 92, 119, 163, 166, 168, 181, 187, 194, 216, 240, 241, 248, \\\n",
    "# 253, 271, 272, 273, 282, 285, 287, 295, 305, 306, 336, 337, 339, 341, 351, 352, 488, \\\n",
    "# 495, 503, 511, 544, 588, 593, 641, 764, 1063, 1090, 1100, 1126, 1395, 1461, 1509, 1523, 1834, 1848, 1872]\n",
    "scores_lasso = model_fit_predict(X_train[:,feaures_columns],X_test[:,feaures_columns],y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA feature reduction\n",
    "n = 50\n",
    "X_train_pca, X_test_pca = pcaSelection(X_train, X_test, n)\n",
    "scores_pca = model_fit_predict(X_train_pca,X_test_pca,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-19 17:20:37,095 - GDC - INFO] X_train size after PCA: (8040, 50)\n",
      "[2018-10-19 17:20:37,096 - GDC - INFO] X_test size after PCA: (3446, 50)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TSNE' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2a9829a5a279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcaSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_tsne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsneSelection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscores_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tsne\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test_tsne\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3aa6271790b2>\u001b[0m in \u001b[0;36mtsneSelection\u001b[0;34m(X_train, X_test, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mX_test_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train size after PCA: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TSNE' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "# PCA+tSNE feature reduction\n",
    "n1 = 50\n",
    "n2 =3\n",
    "X_train_pca, X_test_pca = pcaSelection(X_train, X_test, n1)\n",
    "X_train_tsne, X_test_tsne = tsneSelection(X_train_pca, X_test_pca, n2)\n",
    "scores_tsne = model_fit_predict(X_train_tsne,X_test_tsne,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
